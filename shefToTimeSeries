#!/bin/python3
import argparse, logging, os, re, sys
from collections import namedtuple
from datetime    import datetime
from datetime    import timedelta
from io          import BufferedRandom
from io          import TextIOWrapper
from pathlib     import Path
from typing      import TextIO
from typing      import Union

progname          = Path(sys.argv[0]).stem
version           = "1.0.0"
version_date      = "06Jun2024"

one_day = timedelta(days=1)
month_interval = timedelta(days=30)
month_tolerance = (month_interval - 2 * one_day, month_interval + one_day)
year_interval = timedelta(days=365)
year_tolerance = (year_interval, year_interval + one_day)

dssvue_transform_pattern = re.compile(r"dssvue\[(.+?)\]\[(.+?)\]", re.I)

ShefValue = namedtuple("ShefValue", [
    "location",
    "obs_date",
    "obs_time",
    "create_date",
    "create_time",
    "parameter_code",
    "value",
    "data_qualifier",
    "revised_code",
    "time_series_code",
    "comment"])

class InputException(Exception) :
    pass

class TransformException(Exception) :
    pass

class UndoableInput :
    '''
    Class to read lines from a file-like object, with the ability to undo the last read
    '''
    def __init__(self, input):
        self._input = input
        self._line = None
        self._buffer = []

    def readline(self):
        if self._buffer:
            self._line = self._buffer.pop()
            return self._line
        else:
            self._line = self._input.readline().rstrip()
            return self._line

    def undo(self):
        if self._buffer:
            raise InputException("readline() not called since last undo()")
        elif not self._line :
            raise InputException("Nothing to undo")
        else:
            self._buffer = [self._line]
            self._line = None

class Output :
    def __init__(self, output_object: Union[TextIO, str], append: bool) -> str :
        '''
        Attach the data output device, opening if necessary
        '''
        if isinstance(output_object, (BufferedRandom, TextIOWrapper)) :
            self._output = output_object
            self._output_name = output_object.name
        elif isinstance(output_object, str) :
            self._output = open(output_object, "a+b" if append else "w+b")
            self._output_name = output_object
        else :
            raise Exception(f"Expected BufferedRandom or str object, got [{output_object.__class__.__name__}]")
        
    @property
    def name(self) :
        return self._output_name

    def write(self, s: str) -> None :
        if isinstance(self._output, TextIOWrapper) :
            self._output.write(s)
        elif isinstance(self._output, BufferedRandom) :
            self._output.write(s.encode("utf-8"))

class NullTransformer :
    def __init__(self, logger: Union[None, logging.Logger]) -> None :
        self._logger = logger
        self._shefValue = None

    def assertValueIsSet(self) -> None :
        if not self._shefValue :
            raise TransformException("setvalue() has not been called on transformer")

    def assertUseValue(self) -> None :
        if not self.use_value() :
            raise TransformException(f"Transformer does not use value {self.value_name()}")

    def setShefValue(self, value: ShefValue) -> None :
        self._shefValue = value

    @property
    def transformer_name(self) :
        return self.__class__.__name__

    @property
    def use_value(self) -> bool :
        self.assertValueIsSet()
        return True

    @property
    def location(self) -> str :
        self.assertValueIsSet()
        return f"{self._shefValue.location}"

    @property
    def value_name(self) -> str :
        self.assertValueIsSet()
        return f"{self._shefValue.location}.{self._shefValue.parameter_code}"

    @property
    def loading_info(self) -> dict :
        self.assertValueIsSet()
        return {}

    @property
    def date_time(self) -> str :
        self.assertValueIsSet()
        return f"{self._shefValue.obs_date} {self._shefValue.obs_time}"

    @property
    def forecast_date_time(self) -> str :
        self.assertValueIsSet()
        return None  if self._shefValue.create_date == "0000-00-00" else f"{self._shefValue.create_date} {self._shefValue.create_time}"

    @property
    def parameter(self) -> str :
        self.assertValueIsSet()
        return f"{self._shefValue.parameter_code}"

    @property
    def value(self) -> float :
        self.assertValueIsSet()
        return f"{self._shefValue.value}"

    @property
    def data_qualifier(self) -> str :
        self.assertValueIsSet()
        return f"{self._shefValue.data_qualifier}"

    @property
    def duration_interval(self) -> timedelta :
        self.assertValueIsSet()
        dv = DURATION_VALUES[self._shefValue.parameter_code[2]]
        if dv > 5000 :
            intvl = timedelta(seconds = 0)
        elif dv == 4001 :
            intvl = timedelta(days = 365)
        elif dv == 3001 :
            intvl = timedelta(days = 30)
        elif dv > 2000 :
            intvl = timedelta(days = dv % 1000)
        elif dv > 1000 :
            intvl = timedelta(hours = dv % 1000)
        else :
            intvl = timedelta(minutes = dv % 1000)
        return intvl

class DssVueTransformer (NullTransformer) :
    duration_units = {
        'M' : "Minutes",
        'H' : "Hours",
        'D' : "Days",
        'L' : "Months",
        'Y' : "Years"}

    valueUnitsPattern = re.compile("([0-9]+)([a-z]+)", re.I)

    def __init__(self, logger: Union[None, logging.Logger], sensorFilename: str, parameterFileName: str) -> None :
        super().__init__(logger)
        self._sensors = {}
        self._parameters = {}
        if not os.path.exists(sensorFilename) or not os.path.isfile(sensorFilename) :
            raise TransformException(f"Specified sensor file doesn't exist; [{sensorFilename}]")
        if not os.path.exists(parameterFileName) or not os.path.isfile(parameterFileName) :
            raise TransformException(f"Specified parameter file doesn't exist; [{parameterFileName}]")
        if logger :
            logger.info(f"Using {self.transformer_name}\n\tsensor file    = {sensorFilename}\n\tparameter file = {parameterFileName}")
        #----------------------#
        # load the sensor file #
        #----------------------#
        with open(sensorFilename) as f :
            lines = f.read().strip().split("\n")
        for i in range(len(lines)) :
            line = lines[i]
            if not line or line[0] == '*' or not line[:10].strip() :
                continue
            try :
                location = line[:8].strip()
                pe_code = line[8:10].strip()
                if pe_code in SEND_CODES :
                    pe_code = SEND_CODES[pe_code][0][:2]
                sensor = f"{location}/{pe_code}"
                duration_str = line[10:15].strip()
                if duration_str :
                    duration_value = int(duration_str[:-1])
                    if duration_value == 0 :
                        duration = "IR-Month"
                    else :
                        duration_unit=DssVueTransformer.duration_units[line[14].strip()]
                        if duration_value == 1 :
                            duration_unit = duration_unit[:-1]
                        duration = f"{duration_value}{duration_unit}"
                        if duration == "7Days" :
                            duration = "1Week"
                else :
                    duration = "IR-Month"
                a_part = line[16:33].strip()
                b_part = line[33:50].strip()
                f_part = line[50:67].strip()
                self._sensors[sensor] = {
                    "duration" : duration,
                    "a_part"   : a_part,
                    "b_part"   : b_part,
                    "f_part"   : f_part
                }
            except Exception as e :
                if self._logger :
                    self._logger.error(f"{str(e)} on {sensorFilename}:{i+1}")
        #-------------------------#
        # load the parameter file #
        #-------------------------#
        with open(parameterFileName) as f :
            lines = f.read().strip().split("\n")
        for i in range(len(lines)) :
            line = lines[i]
            if not line or line[0] == '*' or not line[:2].strip() :
                continue
            try :
                pe_code = line[:2].strip()
                c_part = line[3:27].strip()
                unit = line[29:36].strip()
                data_type = line[38:45].strip()
                transform = line[47:56].strip()
                self._parameters[pe_code] = {
                    "c_part"    : c_part,
                    "unit"      : unit,
                    "type"      : data_type,
                    "transform" : transform}
            except Exception as e :
                raise TransformException(f"{str(e)} on {parameterFileName}:{i+1}")
        #--------------------------------------------------------------------#
        # verify all the PE codes in the sensors have an entry in parameters #
        #--------------------------------------------------------------------#
        deleted_sensors = []
        for sensor in self._sensors :
            pe_code = sensor.split("/")[1]
            if pe_code not in self._parameters :
                deleted_sensors.append(sensor)
                if self._logger :
                    self._logger.warning(f"Sensor [{sensor}] in [{sensorFilename}] will not be used, no entry for [{pe_code}] in [{parameterFileName}]")
        for sensor in deleted_sensors :
            del self._sensors[sensor]

    def assertUseValue(self) -> None :
        if not self.use_value :
            raise TransformException(f"Transformer does not use value {self.value_name()}")

    @property
    def sensor(self) -> str :
        self.assertValueIsSet()
        return f"{self._shefValue.location}/{self._shefValue.parameter_code[:2]}"

    @property
    def use_value(self) -> bool :
        self.assertValueIsSet()
        return self.sensor in self._sensors

    @property
    def location(self) -> str :
        self.assertUseValue()
        return self.sensor["b_bpart"]

    @property
    def value_name(self) -> str :
        self.assertUseValue()
        sensor = self._sensors[self.sensor]
        a_part = sensor["a_part"]
        b_part = sensor["b_part"]
        c_part = self.parameter
        e_part = sensor["duration"]
        f_part = sensor["f_part"]
        if f_part == "*" :
            create_date = self._shefValue.create_date
            if create_date == "0000-00-00" :
                f_part = ""
            else :
                create_time = self._shefValue.create_time
                y, m, d = create_date.split("-")
                h, n, s = create_time.split(":")
                f_part = f"T:{y}{m}{d}-{h}{n}|"
        return f"/{a_part}/{b_part}/{c_part}//{e_part}/{f_part}/"

    @property
    def loading_info(self) -> dict :
        param = self._parameters[self.sensor.split("/")[1]]
        specified_type = param["type"]
        pe_code = self._shefValue.parameter_code[:2]
        duration_code = self._shefValue.parameter_code[2]
        if specified_type == "*" :
            parameter_code = self._shefValue.parameter_code
            if duration_code == 'I' :
                data_type = "INST-CUM" if pe_code == "PC" else "INST-VAL"
            else :
                if pe_code in ("CV") :
                    data_type = "PER-AVER"
                elif parameter_code in ("HGIRZNZ", "QRIRZNZ", "TAIRZNZ") :
                    data_type = "PER-MIN"
                elif parameter_code in ("HGIRZXZ", "QZIRZXZ", "TAIRZXZ"):
                    data_type = "PER-MAX"
                elif pe_code in ("RI", "UC", "UL") :
                    data_type = "PER-CUM"
                else :
                    data_type = "INST-VAL"
        else :
            data_type = specified_type
        return {"unit" : param["unit"], "type" : data_type}

    @property
    def parameter(self) -> str :
        self.assertUseValue()
        pe_code = self._shefValue.parameter_code[:2]
        param = self._parameters[pe_code]["c_part"]
        if not param :
            raise TransformException(f"No C Pathname part specified for PE code {pe_code}")
        return param

    @property
    def value(self) -> float :
        val = self._shefValue.value
        pe_code = self._shefValue.parameter_code[:2]
        transform = self._parameters[pe_code]["transform"]
        if not transform :
            #---------------------------------------------#
            # null transform - set to default for PE code #
            #---------------------------------------------#
            if pe_code in ("AT", "AU", "AW") :
                transform = "hmh2"
            elif pe_code in ("VK", "VL", "VM", "VR") :
                transform = "dur2h"
            else :
                transform = "1"
        if transform == "hm2h" :
            #--------------------------------#
            # hrs/minutes to hours transform #
            #--------------------------------#
            expected_pe_codes = ("AT", "AU", "AW")
            if pe_code not in expected_pe_codes :
                if self._logger :
                    self._logger.warning(f"Transform of {transform} used with unexpected PE code [{pe_code}] - normally only for {','.join(expected_pe_codes)}")
            hours = val // 100
            minutes = val % 100
            if minutes < 60 :
                val = hours + minutes / 60.
            else :
                if self._logger :
                    self._logger.warning(f"Transform [{transform}] is not valid for value [{val}], value not transformed")
        elif transform == "dur2h" :
            #-----------------------------#
            # duration to hours transform #
            #-----------------------------#
            expected_pe_codes = ("VK", "VL", "VM", "VR")
            duration = self._sensors[self.sensor]["duration"]
            m = DssVueTransformer.valueUnitsPattern.match(duration)
            if not m :
                if self._logger :
                    self._logger.warning(
                        f"Cannot use transform [{transform}] on duration [{duration}] for sensor [{self.sensor}]"
                        f"\n\tUsing data value [{val}] as MWh")
                factor = 1
            else :
                duration_value = int(m.group(1))
                duration_unit  = m.group(2)
                if duration_unit.startswith("Minute") :
                    factor = duration_value / 60
                elif duration_unit.startswith("Hour") :
                    factor = duration_value
                elif duration_unit.startswith("Day") :
                    factor = duration_value * 24
                elif duration_unit.startswith("Month") :
                    factor = duration_value * 24 * 30
                elif duration_unit.startswith("Year") :
                    factor = duration_value * 24 * 65
                else :
                    raise TransformException(f"Unexpected duration unit [{duration_unit}]")
            if pe_code not in expected_pe_codes :
                if self._logger :
                    self._logger.warning(f"Transform of {transform} used with unexpected PE code [{pe_code}] - normally only for {','.join(expected_pe_codes)}")
            val *= factor
        else :
            #------------------#
            # scalar transform #
            #------------------#
            val *= float(transform)
        if val == -9999. :
            val = None
        return val

DURATION_CODES    = {
       0 : 'I',    1 : 'U',    5 : 'E',   10 : 'G',   15 : 'C',
      30 : 'J', 1001 : 'H', 1002 : 'B', 1003 : 'T', 1004 : 'F',
    1006 : 'Q', 1008 : 'A', 1012 : 'K', 1018 : 'L', 2001 : 'D',
    2007 : 'W', 2015 : 'N', 3001 : 'M', 4001 : 'Y', 5000 : 'Z',
    5001 : 'S', 5002 : 'R', 5003 : 'V', 5004 : 'P', 5005 : 'X'}

DURATION_VALUES = {value : key for key, value in DURATION_CODES.items()}

PROBABILITY_CODES = {
     .002 : 'A',  .004 : 'B',   .01 : 'C',   .02 : 'D',   .04 : 'E',   .05 : 'F',
       .1 : '1',    .2 : '2',   .25 : 'G',    .3 : '3',    .4 : '4',    .5 : '5',
       .6 : '6',    .7 : '7',   .75 : 'H',    .8 : '8',    .9 : '9',   .95 : 'T',
      .96 : 'U',   .98 : 'V',   .99 : 'W',  .996 : 'X',  .998 : 'Y', .0013 : 'J',
    .0228 : 'K', .1587 : 'L',  -0.5 : 'M', .8413 : 'N', .9772 : 'P', .9987 : 'Q',
     -1.0 : 'Z'}

PROBABILITY_VALUES = {value : key for key, value in PROBABILITY_CODES.items()}

SEND_CODES = {
    "AD" : ("ADZZZZZ", False), "AT" : ("ATD",     False), "AU" : ("AUD",     False), "AW" : ("AWD",     False), "EA" : ("EAD",     False),
    "EM" : ("EMD",     False), "EP" : ("EPD",     False), "ER" : ("ERD",     False), "ET" : ("ETD",     False), "EV" : ("EVD",     False),
    "HN" : ("HGIRZNZ", False), "HX" : ("HGIRZXZ", False), "HY" : ("HGIRZZZ", True) , "LC" : ("LCD",     False), "PF" : ("PPTCF",   False),
    "PY" : ("PPDRZZZ", True) , "PP" : ("PPD",     False), "PR" : ("PRD",     False), "QC" : ("QCD",     False), "QN" : ("QRIRZNZ", False),
    "QX" : ("QRIRZXZ", False), "QY" : ("QRIRZZZ", True) , "SF" : ("SFD",     False), "TN" : ("TAIRZNZ", False), "QV" : ("QVZ",     False),
    "RI" : ("RID",     False), "RP" : ("RPD",     False), "RT" : ("RTD",     False), "TC" : ("TCS",     False), "TF" : ("TFS",     False),
    "TH" : ("THS",     False), "TX" : ("TAIRZXZ", False), "UC" : ("UCD",     False), "UL" : ("ULD",     False), "XG" : ("XGJ",     False),
    "XP" : ("XPQ",     False)}

format_1_pattern = re.compile(
# groups:  1 - Location
#          2 - Obs date
#          3 - Obs time
#          4 - Create date
#          5 - Create time
#          6 - PEDTSE
#          7 - Value
#          8 - Data qualifier
#          9 - Probability code number
#         10 - Reivsed code
#         11 - Time series code
#         12 - Message source (.B only)
#         13 - Comment
#     1       2                   3                    4                   5                   6
    r"(\w+\s*)(\d{4}-\d{2}-\d{2}) (\d{2}:\d{2}:\d{2})  (\d{4}-\d{2}-\d{2}) (\d{2}:\d{2}:\d{2})  ([A-Z]{3}[A-Z0-9]{3})." +\
#                                                  1      1        1                1
#     7               8      9                     0      1        2                3
    r"([ 0-9.+-]{15}) ([A-Z])([ 0-9.+-]{9})  \d{4} ([01]) ([012])  ((?: |\w){8})  \"(.+)\"")
format_2_pattern = re.compile(
# groups:  1 - Location
#          2 - Obs year
#          3 - Obs month
#          4 - Obs day
#          5 - Obs hour
#          6 - Obs minute
#          7 - Obs second
#          8 - Create year
#          9 - Create month
#         10 - Create day
#         11 - Create hour
#         12 - Create minute
#         13 - Create second
#         14 - PE code
#         15 - TS code
#         16 - Extremum code
#         17 - Value
#         18 - Data qualifier
#         19 - Probability code number
#         20 - Duration code number
#         21 - Revised code
#         22 - Message source (.B only)
#         23 - Time series code
#                                                                                             1         1         1         1
#     1       2      3           4       5         6         7          8           9         0         1         2         3
    r"(\w+\s*)(\d{4})( \d|\d\d)( \d|\d\d)( \d|\d\d)( \d|\d\d)( \d|\d\d) (   0|\d{4})( \d|\d\d)( \d|\d\d)( \d|\d\d)( \d|\d\d)( \d|\d\d)" +\
#      1          1            1      1               1      1             2           2      2            2
#      4          5            6      7               8      9             0           1      2            3
    r" ([A-Z]{2}) ([A-Z0-9]{2})([A-Z])([ 0-9.+-]{10}) ([A-Z])([ 0-9.+-]{6})([ 0-9]{5}) ([01]) ((?: |\w){8})([012])")
format_2_comment_pattern = re.compile(' {8}"(.+)"')

def get_next_value(input: "UndoableInput", m: re.Match, format: int) -> tuple :
    if format == 1 :
        try :
            probability_code = PROBABILITY_CODES[float(m.group(9))]
        except KeyError :
            probability_code = 'Z'
        if len(m.group(1)) != 10 :
            raise ValueError(f"Expected length location group to be 10, got {len(m.group(1))}")
        location = m.group(1).strip()
        obs_date = m.group(2)
        obs_time = m.group(3)
        create_date = m.group(4)
        create_time = m.group(5)
        parameter_code = f"{m.group(6)}{probability_code}"
        value = float(m.group(7))
        data_qualifier = m.group(8)
        revised_code = m.group(10)
        time_series_code = m.group(11)
        comment = m.group(13).strip()
    elif format == 2 :
        try :
            probability_code = PROBABILITY_CODES[float(m.group(19))]
        except KeyError :
            probability_code = 'Z'
        try :
            duration_code = DURATION_CODES[int(m.group(20))]
        except KeyError :
            duration_code = 'V'
        if len(m.group(1)) != 8 :
            raise ValueError(f"Expected length of location group to be 8, got {len(m.group(1))}")
        location = m.group(1).strip()
        obs_date = f"{m.group(2)}-{int(m.group(3)):02d}-{int(m.group(4)):02d}"
        obs_time = f"{int(m.group(5)):02d}:{int(m.group(6)):02d}:{int(m.group(7)):02d}"
        create_date = f"{int(m.group(8)):04d}-{int(m.group(9)):02d}-{int(m.group(10)):02d}"
        create_time = f"{int(m.group(11)):02d}:{int(m.group(12)):02d}:{int(m.group(13)):02d}"
        parameter_code = f"{m.group(14)}{duration_code}{m.group(15)}{m.group(16)}{probability_code}"
        value = float(m.group(17))
        data_qualifier = m.group(18)
        revised_code = m.group(21)
        time_series_code = m.group(23)
        line = input.readline()
        m2 = format_2_comment_pattern.match(line)
        if m2 :
            comment = m2.group(1)
        else :
            comment = ""
            input.undo()
    else :
        raise ValueError(f"Expected format of 1 or 2, got {format}")

    return ShefValue(
        location,
        obs_date,
        obs_time,
        create_date,
        create_time,
        parameter_code,
        value,
        data_qualifier,
        revised_code,
        time_series_code,
        comment)

def get_datetime(datetime_str: str) -> datetime :
    global datetime_pattern
    try :
        datetime_pattern
    except NameError :
        datetime_pattern = re.compile("[ :-]")
    return datetime(*tuple(map(int, datetime_pattern.split(datetime_str))))

def output_values(logger: Union[None, logging.Logger], outfile: TextIO, name: str, info: dict, duration_interval: timedelta, values: list) -> tuple :
    if values :
        for v in values :
            if v[1] is None :
                if logger :
                    logger.debug(f"Discarding missing value at [{v[0]}] for [{name}]")
        values = [v for v in values if v[1] is not None]
    if values :
        load_individually = False
        values.sort()
        if len(values) > 1 :
            if duration_interval :
                #---------------------------------------------------#
                # see if we the value times agree with the duration #
                #---------------------------------------------------#
                intervals = set()
                for i in range(1, len(values)) :
                    intervals.add(get_datetime(values[i][0]) - get_datetime(values[i-1][0]))
                for intvl in sorted(intervals) :
                    if intvl / duration_interval != intvl // duration_interval :
                        if duration_interval == month_interval and month_tolerance[0] <= intvl <= month_tolerance[1] :
                            pass
                        elif duration_interval == year_interval and year_tolerance[0] <= intvl <= year_tolerance[1] :
                            pass
                        else :
                            logger.warning(
                                f"Data interval of [{str(intvl)}] does not agree with duration of [{str(duration_interval)}]"
                                f"\n\ton [{name}]\n\tWill attempt to load [{len(values)}] values individually")
                            load_individually = True
        if load_individually :
            #------------------------------------------#
            # load values one at a time, some may fail #
            #------------------------------------------#
            for value in values :
                outfile.write(f"{name}\n\t{info}\n")
                outfile.write(f"\t{value}\n")
            time_series_count = len(values)
        else :
            #---------------------------------------------#
            # load values in one or more chunks, skipping #
            # gaps to prevent overriting with missing     #
            #---------------------------------------------#
            slices = []
            start = 0
            if duration_interval :
                for i in range(1, len(values)) :
                    interval = get_datetime(values[i][0]) - get_datetime(values[i-1][0])
                    if interval > duration_interval * 1.5 :
                        slices.append(slice(start, i, 1))
                        start = i
            slices.append(slice(start, len(values), 1))
            for i in range(len(slices)) :
                outfile.write(f"{name}\n\t{info}\n")
                for value in values[slices[i]] :
                    outfile.write(f"\t{value}\n")
            time_series_count = len(slices)
        value_count = len(values)
    else :
        logger.info(f"No values for [{name}]")
        value_count = time_series_count = 0
    return value_count, time_series_count

def main() -> None :
    '''
    Driver routine
    '''
    global logger
    start_time = datetime.now()
    #--------------------#
    # parse command line #
    #--------------------#
    argparser = argparse.ArgumentParser(
        formatter_class = argparse.RawDescriptionHelpFormatter,
        description="Parses SHEF messages into different output formats")
    argparser.add_argument(
        "-i",
        "--in",
        action="store",
        default=sys.stdin,
        metavar="input_filename",
        help="input file (defaults to <stdin>)")
    argparser.add_argument(
        "-o",
        "--out",
        action="store",
        default=sys.stdout,
        metavar="output_filename",
        help="output file (defaults to <stdout>)")
    argparser.add_argument(
        "-l",
        "--log",
        action="store",
        default=sys.stderr,
        metavar="log_filename",
        help="log file (defaults to <sterr>)")
    argparser.add_argument(
        "-t",
        "--transformer",
        action="store",
        default=None,
        help="transformation specification")
    argparser.add_argument(
        "-v",
        "--loglevel",
        action="store",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        default="INFO",
        help="verbosity/logging level (defaults to INFO)")
    argparser.add_argument(
        "--timestamps",
        action="store_true",
        help="timestamp log output")
    argparser.add_argument(
        "--append_out",
        action="store_true",
        help="append to output file instead of overwriting")
    argparser.add_argument(
        "--append_log",
        action="store_true",
        help="append to log file instead of overwriting")
    args = argparser.parse_args()

    datefmt = "%Y-%m-%d %H:%M:%S"
    if args.timestamps :
        format  = "%(asctime)s %(levelname)s: %(msg)s"
    else :
        format  = "%(levelname)s: %(msg)s"
    level  = {
        "DEBUG"    : logging.DEBUG,
        "INFO"     : logging.INFO,
        "WARNING"  : logging.WARNING,
        "ERROR"    : logging.ERROR,
        "CRITICAL" : logging.CRITICAL,
        "ALL"      : logging.NOTSET}[args.loglevel]
    if isinstance(args.log, str) :
        if os.path.exists(args.log) :
            if not os.path.isfile(args.log) :
                raise Exception(f"{args.log} is not a regular file")
            if not args.append_log :
                os.remove(args.log)
        logging.basicConfig(filename=args.log, format=format, datefmt=datefmt, level=level)
        logfile_name = args.log
    else :
        logging.basicConfig(stream=args.log, format=format, datefmt=datefmt, level=level)
        logfile_name = args.log.name
    logger  = logging.getLogger(progname)
    if isinstance(getattr(args, "in"), str) :
        infile_name = getattr(args, "in")
        infile = open(infile_name)
    else :
        infile_name = getattr(args, "in").name
        infile = getattr(args, "in")
    outfile = Output(args.out, args.append_out)
    outfile_name = outfile.name
    if len(sys.argv) == 1 :
        logger.info("")
        logger.info(f"Use '{progname} -h' for help")
        logger.info("")
        logger.info(f"Reading from {infile_name}, press ^D (^Z+Enter on Windows) to exit")
        logger.info("")
    logger.info("----------------------------------------------------------------------")
    logger.info(f"Program {progname} version {version} ({version_date}) starting up")
    logger.info("----------------------------------------------------------------------")
    logger.debug(f"Input file set to {infile_name}")
    logger.debug(f"Output file set to {outfile_name}")
    logger.debug(f"Log file set to {logfile_name}")
    if args.transformer :
        if dssvue_transform_pattern.match(args.transformer) :
            m = dssvue_transform_pattern.match(args.transformer)
            transformer = DssVueTransformer(logger, m.group(1), m.group(2))
    else :
        transformer = NullTransformer(logger)
    
    line_number       = 0
    value_count       = 0
    time_series_count = 0
    input_format      = None
    #----------------------------------------#
    # read the input and generate the output #
    #----------------------------------------#
    input = UndoableInput(infile)
    line = input.readline()
    last_name = None
    last_info = None
    last_duration_interval = None
    while line :
        line_number += 1
        if input_format is None :
            #---------------------------------#
            # auto-determine the input format #
            #---------------------------------#
            m = format_1_pattern.match(line)
            if not m :
                m = format_2_pattern.match(line)
                if not m :
                    logger.critical(f"Unrecognized format on {infile_name}:{line_number} [{line}]")
                    exit(-1)
                input_format = 2
            else :
                input_format = 1
        elif input_format == 1 :
            #------------------------------------#
            # shefParser -f 1 (shefit -1) format #
            #------------------------------------#
            m = format_1_pattern.match(line)
            if not m :
                logger.critical(f"Format is not shefParser --format 1 on {infile_name}:{line_number} [{line}]")
                exit(-1)
        elif input_format == 2 :
            #------------------------------------#
            # shefParser -f 2 (shefit -2) format #
            #------------------------------------#
            m = format_2_pattern.match(line)
            if not m :
                logger.critical(f"Format is not shefParser --format 2 on {infile_name}:{line_number} [{line}]")
                exit(-1)
        v = get_next_value(input, m, input_format)
        transformer.setShefValue(v)
        if not transformer.use_value :
            logger.info(f"No sensor information for {v.location}/{v.parameter_code[:2]}")
        else :
            try :
                name = transformer.value_name
                if name != last_name :
                    try :
                        if last_name :
                            v_count, ts_count = output_values(logger, outfile, last_name, last_info, last_duration_interval, values)
                            value_count += v_count
                            time_series_count += ts_count
                    except TransformException as te :
                        logger.error(str(te))
                    values = []
                    duration_interval = transformer.duration_interval
                    info = transformer.loading_info
                last_name = name
                last_info = info
                last_duration_interval = duration_interval
                values.append([transformer.date_time, transformer.value])
            except TransformException as te :
                logger.error(str(te))
        line = input.readline()
    try :
        if values :
            for v in values :
                if v[1] is None :
                    logger.debug(f"Discarding missing value at [{v[0]}] for [{name}]")
            values = [v for v in values if v[1] is not None]
        if values :
            v_count, ts_count = output_values(logger, outfile, name, info, duration_interval, values)
            value_count += v_count
            time_series_count += ts_count
    except TransformException as te :
        logger.error(str(te))
    logger.info("")
    logger.info("--[Summary]-----------------------------------------------------------")
    logger.info(f"Program    = {progname} version {version} ({version_date})")
    logger.info(f"Start Time = {str(start_time)[:-7]}")
    logger.info(f"Run Time   = {str(datetime.now() - start_time)[:-3]}")
    logger.info(f"{line_number:6d} lines read from {infile_name}")
    logger.info(f"{value_count:6d} values in {time_series_count} time series output to {outfile_name} using {transformer.__class__.__name__}")

if __name__ == "__main__" :
    main()
